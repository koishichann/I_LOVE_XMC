#! /bin/zsh
#conda activate ddd
#nohup python -u ./src/main_run.py --datadir='./dataset/Wiki10-31K/' --istrain=1 --is_pred_trn=1 --is_pred_tst=1 --iscombine=1 --is_rank_train=1 --is_ranking=1 --combine_model='cross-encoder/stsb-roberta-base' --modelname='t5' --outputmodel='t5_save' --batch_size=8 --epoch=10 --checkdir='t5_check' --data_size=4  --rank_model='all-MiniLM-L6-v2' --rank_batch=128 --rankmodel_save='bi_en_t5'>> ./log/output.log 2>&1 &
#python -u ./main.py --dataset=eurlex-4k --datadir=./dataset --is_kg_train=1 --is_pred_trn=1 --is_pred_tst=1 --is_combine=1 --is_rank_train=1 --is_rank=1 --kg_type=bart --combine_type=bi --rank_type=bi --kg_epoch=5 --kg_batch_size=4 --kg_checkdir=bart_check --kg_savedir=bart_save --kg_lr=5e-5 --combine_model_name=sentence-transformers/all-mpnet-base-v2 --rank_model=sentence-transformers/all-mpnet-base-v2 --rank_batch=32 --rank_epoch=3 --rank_model_save=bi_rank --max_len=512 --kg_model_name=facebook/bart-base --prefix_token_num=300

python -u ./main.py --dataset=eurlex-4k --datadir=./dataset --is_kg_train=1 --is_pred_trn=1 --is_pred_tst=1 --is_combine=1 --is_rank_train=1 --is_rank=1 --kg_type=two-bart-kpappend_a --combine_type=bi --rank_type=bi --kg_epoch=5 --kg_batch_size=8 --kg_checkdir=bart_check --kg_savedir=bart_save --kg_lr=5e-5 --combine_model_name=sentence-transformers/all-mpnet-base-v2 --rank_model=sentence-transformers/all-mpnet-base-v2 --rank_batch=32 --rank_epoch=3 --rank_model_save=bi_rank --max_len=1024 --kg_model_name=facebook/bart-base --prefix_token_num=25 --kpdrop_rate=0.7 --kpappend_rate=0.7 --match=stem --stem_lambda=0.5 --stem_delta=0.5 --stem_model=sentence-transformers/all-mpnet-base-v2
python -u ./main.py --dataset=eurlex-4k --datadir=./dataset --is_kg_train=1 --is_pred_trn=1 --is_pred_tst=1 --is_combine=1 --is_rank_train=1 --is_rank=1 --kg_type=two-bart-kpappend_r --combine_type=bi --rank_type=bi --kg_epoch=5 --kg_batch_size=8 --kg_checkdir=bart_check --kg_savedir=bart_save --kg_lr=5e-5 --combine_model_name=sentence-transformers/all-mpnet-base-v2 --rank_model=sentence-transformers/all-mpnet-base-v2 --rank_batch=32 --rank_epoch=3 --rank_model_save=bi_rank --max_len=1024 --kg_model_name=facebook/bart-base --prefix_token_num=25 --kpdrop_rate=0.7 --kpappend_rate=0.7 --match=stem --stem_lambda=0.5 --stem_delta=0.5 --stem_model=sentence-transformers/all-mpnet-base-v2
python -u ./main.py --dataset=eurlex-4k --datadir=./dataset --is_kg_train=1 --is_pred_trn=1 --is_pred_tst=1 --is_combine=1 --is_rank_train=1 --is_rank=1 --kg_type=two-bart-kpappend_na --combine_type=bi --rank_type=bi --kg_epoch=5 --kg_batch_size=8 --kg_checkdir=bart_check --kg_savedir=bart_save --kg_lr=5e-5 --combine_model_name=sentence-transformers/all-mpnet-base-v2 --rank_model=sentence-transformers/all-mpnet-base-v2 --rank_batch=32 --rank_epoch=3 --rank_model_save=bi_rank --max_len=1024 --kg_model_name=facebook/bart-base --prefix_token_num=25 --kpdrop_rate=0.7 --kpappend_rate=0.7 --match=stem --stem_lambda=0.5 --stem_delta=0.5 --stem_model=sentence-transformers/all-mpnet-base-v2
python -u ./main.py --dataset=eurlex-4k --datadir=./dataset --is_kg_train=1 --is_pred_trn=1 --is_pred_tst=1 --is_combine=1 --is_rank_train=1 --is_rank=1 --kg_type=two-bart-kpappend_nr --combine_type=bi --rank_type=bi --kg_epoch=5 --kg_batch_size=8 --kg_checkdir=bart_check --kg_savedir=bart_save --kg_lr=5e-5 --combine_model_name=sentence-transformers/all-mpnet-base-v2 --rank_model=sentence-transformers/all-mpnet-base-v2 --rank_batch=32 --rank_epoch=3 --rank_model_save=bi_rank --max_len=1024 --kg_model_name=facebook/bart-base --prefix_token_num=25 --kpdrop_rate=0.7 --kpappend_rate=0.7 --match=stem --stem_lambda=0.5 --stem_delta=0.5 --stem_model=sentence-transformers/all-mpnet-base-v2
